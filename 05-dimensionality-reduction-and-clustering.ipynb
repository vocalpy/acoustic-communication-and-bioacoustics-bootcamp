{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4075c51-c1c4-4977-b709-7aebebb8068b",
   "metadata": {},
   "source": [
    "## Dimensionality reduction and clustering\n",
    "\n",
    "Material here is adapted in part from [this tutorial](https://github.com/marathomas/tutorial_repo) shared under CC-BY-4.0 license, that accompanied [this paper](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13754).\n",
    "\n",
    "We are using a (very tiny!) sub-set of the [Jourjine et al. 2023 dataset]() that accompanied the paper [\"Two pup vocalization types are genetically and functionally separable in deer mice\"](https://www.cell.com/current-biology/fulltext/S0960-9822(23)00185-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0960982223001859%3Fshowall%3Dtrue). Some code is also adapted from the [repository that reproduces the paper results](https://github.com/nickjourjine/peromyscus-pup-vocal-evolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976b1ca-9092-4ed9-8729-9004f7acdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import hdbscan\n",
    "import vocalpy as voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba214a-4043-4431-9d29-3cb55f62c1c1",
   "metadata": {},
   "source": [
    "## Load mouse pup call data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874ce2e-db35-483a-a73b-eb5dcd6d696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twocalls_dir = pathlib.Path(\"data/Jourjine-et-al-2023-two-pup-calls-subset/\")\n",
    "# next line, [0] because there's just one wav file\n",
    "wav_path = voc.paths.from_dir(twocalls_dir / \"audio\", \"wav\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e794db8-992b-4dd4-b584-abe9d6541764",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_df = pd.read_csv(twocalls_dir / \"segments\" / \n",
    "                      \"GO_24860x23748_ltr2_pup3_ch4_4800_m_337_295_fr1_p9_2021-10-02_12-35-01.csv\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3ff8e-22c0-48d3-b1e3-d8b7838394e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3d213-419d-4fb6-9fa4-a42546380755",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sounds = []\n",
    "sound = voc.Sound.read(wav_path)\n",
    "# ---- iterate through all the syllables in this annotation\n",
    "for start_s, stop_s in zip(\n",
    "    segs_df.start_seconds.values, segs_df.stop_seconds.values\n",
    "):\n",
    "    # ---- make a new sound with the audio data for just this syllable\n",
    "    start_ind = int(start_s * sound.samplerate)\n",
    "    stop_ind = int(stop_s * sound.samplerate)\n",
    "    all_sounds.append(\n",
    "        voc.Sound(\n",
    "            data=sound.data[:, start_ind:stop_ind],\n",
    "            samplerate=sound.samplerate\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a0655-da3f-4750-b10d-69fcb424ee7a",
   "metadata": {},
   "source": [
    "We write a function to give us back Mel spectrograms, so we can parallelize processing with VocalPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8dc5c-389b-44b9-8678-b49c41a41687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram(\n",
    "    sound: voc.Sound, n_mels: int=50, window: str = \"hann\", \n",
    "    n_fft: int = 512, hop_length: int = 128, fmin=5000, fmax=125000\n",
    ") -> voc.Spectrogram:\n",
    "    S = librosa.feature.melspectrogram(y=sound.data,\n",
    "                                       sr=sound.samplerate, \n",
    "                                       n_mels=n_mels , \n",
    "                                       fmax=fmax, \n",
    "                                       fmin=fmin,\n",
    "                                       n_fft=n_fft,\n",
    "                                       hop_length=hop_length, \n",
    "                                       window=window, \n",
    "                                       win_length=n_fft)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    t = librosa.frames_to_time(frames=np.arange(S.shape[-1]), sr=sound.samplerate, hop_length=hop_length)\n",
    "    f = librosa.mel_frequencies(n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "    return voc.Spectrogram(data=S[0, ...], frequencies=f, times=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed32720-5136-4cd5-9e7a-3e8357298a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = melspectrogram\n",
    "\n",
    "spect_maker = voc.SpectrogramMaker(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f706f1-25d3-49a1-83d6-16d647956ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spects = spect_maker.make(all_sounds, parallelize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a621a36-0738-4e25-a5f7-fc7841b53ab1",
   "metadata": {},
   "source": [
    "Now we get the numpy arrays directly, and we throw away the channel dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbbf4b-1730-49f9-8a57-f27ce8913356",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spects = [\n",
    "    spect.data[0, ...]\n",
    "    for spect in all_spects\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0631ae0-bd54-450d-86d4-b141bae2de95",
   "metadata": {},
   "source": [
    "This should give us a two-dimensional array, with dimensions (frequency, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f91ea-31f4-4b39-8cff-a7cd2c82afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spects[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebdf66-36d0-4327-b0b6-67a9e8ba61ba",
   "metadata": {},
   "source": [
    "Let's visualize a random subset, just to inspect our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b5788-0d29-4556-81d7-2479e00fb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "fig, ax_arr = plt.subplots(4, 6)\n",
    "ax_arr = ax_arr.ravel()\n",
    "for ax, spect in zip(ax_arr, random.sample(all_spects, len(all_spects))):\n",
    "    ax.pcolormesh(spect)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272377bc-b42d-45c2-b0f8-cb7204a99266",
   "metadata": {},
   "source": [
    "Now we need to know the maximum number of time bins in any of the spectrograms, so we can pad all the spectrograms to the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af47b2-089c-4bd2-9f0f-298970b0bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width = np.max([\n",
    "    spect.data.shape[1] for spect in all_spects   \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979a1e7-4495-4fd5-9aeb-81b8d890bf3b",
   "metadata": {},
   "source": [
    "We also use the minimum value to pad, so we don't add some very large value in the padding, that could impact the UMAP calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a3dc6-ca23-4d53-8329-c9b900a12d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min([spect.min() for spect in all_spects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4fba9-489c-4d4d-9d46-c79e7dad49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_spect(spect, max_width=max_width, constant_values=min_val):\n",
    "    pad_width = max_width - spect.shape[1]\n",
    "    # pad with half the width needed on both sides\n",
    "    left_pad = pad_width // 2\n",
    "    right_pad = pad_width - left_pad\n",
    "    return np.pad(\n",
    "        spect, ((0, 0), (left_pad, right_pad)), mode='constant', constant_values=min_val,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b1fe8-8d28-4e8e-a261-e197a07ee27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spects = [\n",
    "    pad_spect(spect, max_width)\n",
    "    for spect in all_spects\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff7d70-17de-4e48-a03c-600dea518159",
   "metadata": {},
   "source": [
    "Let's make sure that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59ea5c-edae-4f87-b533-0b20f4160b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(\n",
    "    [spect.shape[1] == max_width for spect in all_spects]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a6ba4-f188-4698-a955-6e8b301add0b",
   "metadata": {},
   "source": [
    "Again we visualize a random sample just to double check things are working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab08d55-8a72-45f0-a151-e61bb830de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "fig, ax_arr = plt.subplots(4, 6)\n",
    "ax_arr = ax_arr.ravel()\n",
    "for ax, spect in zip(ax_arr, random.sample(all_spects, len(all_spects))):\n",
    "    ax.pcolormesh(spect)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f2671-10d2-457b-ae86-b42fc17953a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    spect.flatten() for spect in all_spects\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec8aa9-7295-4eda-b5df-1fc9d9e21b1b",
   "metadata": {},
   "source": [
    "## Dimensionality reduction with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2e2ec-fedb-4e36-bad0-197e84cd63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(\n",
    "    n_components=2, min_dist=0.25, n_neighbors=15, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd4e1b-3a1b-4e26-ae06-60c49e46c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0dd13-0157-4261-8ced-db74d4e6f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b023b95-7d03-4e80-bc73-d800ba7ea188",
   "metadata": {},
   "source": [
    "## Clustering with HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa05551-fcd0-4de9-bab7-31337ce128c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=100, allow_single_cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c2e95-d010-476e-a56b-6a937a5fabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.fit(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5049c-f2d5-4843-a270-4775a0245436",
   "metadata": {},
   "source": [
    "We plot using the \"labels\", that is, the integer class representing the cluster that each data point has been assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb3ab7-dd15-4238-8c08-5e62fd1bd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clusterer.labels_\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.colormaps['tab20'].resampled(np.unique(y).shape[0])\n",
    "c = cmap.colors[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755fbaa-1e29-47ba-91dc-972a8d2ae085",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=c);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
