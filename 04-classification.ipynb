{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec8ff80-592f-423d-9406-bb8e961183af",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this notebook we walk through an example of classifying individual zebra finches using acoustic parameters extracted from their calls.\n",
    "\n",
    "Material here is adapted in part from https://github.com/theunissenlab/BioSoundTutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa86f79-9377-498c-abb9-35c46bdc6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import vocalpy as voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f7cf0-5a49-4db8-bbd3-e1c63b601593",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_paths = voc.paths.from_dir(\n",
    "    './data/Elie-Theunissen-2016-zebra-finch-song-library-subset/',\n",
    "    'wav'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786546d3-5214-427b-a0af-93b0f0d180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec033d-93f2-4ebe-bb47-b26dbf7eae00",
   "metadata": {},
   "source": [
    "We make a helper function to get the bird IDs from the filenames.  \n",
    "\n",
    "We will use this below when we want to predict the bird ID from the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583c7c5-332c-428c-a85a-0c3abc191cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_id_from_path(wav_path):\n",
    "    \"\"\"Helper functoin that gets a bird ID from a path\"\"\"\n",
    "    return wav_path.name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8da74b-9266-4d68-a9aa-fc27dd4e925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_id_from_path(wav_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b8996-af80-4824-9f09-17707cee5b59",
   "metadata": {},
   "source": [
    "We use a list comprehension to get the ID from all 91 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06afac-82c9-4922-ae71-67ab10722967",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_ids = [\n",
    "    bird_id_from_path(wav_path)\n",
    "    for wav_path in wav_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab27b90-4ab3-4a49-a19e-d4fcf87fff72",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Now we extract the acoustic features we will use to classify.  \n",
    "\n",
    "For this example we use the temporal and spectral features from `soundsig`, since those are relatively quick to extract. For an example that uses fundamental frequency estimation, see https://github.com/theunissenlab/BioSoundTutorial/blob/master/BioSound4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8881a-4e33-4f43-b42d-f25a7ed4f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = voc.feature.soundsig.predefined_acoustic_features\n",
    "params = dict(ftr_groups=(\"temporal\", \"spectral\"))\n",
    "extractor = voc.FeatureExtractor(callback, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde332bd-8060-4734-bdbc-1a9949e6e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for wav_path in wav_paths:\n",
    "    data, samplerate = librosa.load(wav_path)\n",
    "    data = librosa.to_mono(data)\n",
    "    sounds.append(\n",
    "        voc.Sound(data, samplerate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7184890-17bb-4c54-8865-fe5d12a68c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = extractor.extract(sounds, parallelize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e52eda-9804-462a-816f-fb5584ed8e1e",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Now what we want to get from our extracted features is two NumPy arrays, `X` and `y`.  \n",
    "\n",
    "These represent the samples $X_i$ in our dataset with their features $x$, and the labels for those samples $y_i$. In this case we have a total of $m=$91 samples (where $i \\in 1, 2, ... m$).\n",
    "\n",
    "We get these arrays as follows (noting there are always multiple ways to do things when you're programming):\n",
    "- Take the `data` attribute of the `Features` we got back from the `FeatureExtractor` and convert it to a `pandas.DataFrame` with one row: the scalar set of features for exactly one sound\n",
    "- Use `pandas` to concatenate all those `DataFrame`s, so we end up with 91 rows\n",
    "- Add a column to this `DataFrame` with the IDs of the birds -- we then have $X$ and $y$ in a single table we could save to a csv file, to do further analysis on later\n",
    "- We get $X$ by using the `values` attribute of the `DataFrame`, which is a numpy array\n",
    "- We get $y$ using `pandas.factorize`, that converts the unique set of strings in the `\"id\"` column into integer class labels: i.e., since there are 4 birds, for every row we get a value from $\\{0, 1, 2, 3\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e0f93-a2b8-47ef-943f-43d464e3ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [features.data.to_pandas()\n",
    "    for features in features_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d33d67-93d1-47c3-810f-8ef4130d2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d0fc1-b0e8-4c0b-b970-f2edd6318cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = pd.array(bird_ids, dtype=\"str\")\n",
    "y, _ = df[\"id\"].factorize()\n",
    "X = df.values[:, :-1]  # -1 because we don't want 'id' column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cbb0c-edd2-4ff8-83bd-928cbf0d52b5",
   "metadata": {},
   "source": [
    "## Fitting a Random Forest classifier\n",
    "\n",
    "Finally we will train a classifer from `scikit-learn` to classify these individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b467c4-99e4-4a65-b2ce-23c39e736365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a96c13-0cce-4c52-b207-58a35bc67bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "    X, y, stratify=y, train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13392d54-3c47-478a-a6f9-b6ae5e33626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc935-d7cb-4b0d-a6ac-62c2bd54fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ada26a-1a24-4faf-a44d-89385350280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Accuracy: {clf.score(X_val, y_val) * 100:0.2f}%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
